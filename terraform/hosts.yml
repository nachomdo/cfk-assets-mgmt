---
all:
  vars:
    ansible_connection: ssh
    ansible_user: ubuntu
    ansible_become: true
    ansible_ssh_private_key_file: /tmp/ssh_priv.pem
    sasl_protocol: plain
    sasl_plain_users:
      admin:
        principal: 'kafka'
        password: 'admin-secret'
      schema_registry:
        principal: 'schema-registry'
        password: 'schema_registry-secret'
      kafka_connect:
        principal: 'kafka-connect'
        password: 'kafka_connect-secret'
      ksql:
        principal: 'ksqldb'
        password: 'ksql-secret'
      kafka_rest:
        principal: 'kafka_rest'
        password: 'kafka_rest-secret'
      control_center:
        principal: 'control-center'
        password: 'control_center-secret'
      kafka_connect_replicator:
        principal: 'kafka_connect_replicator'
        password: 'kafka_connect_replicator-secret'
      client:
        principal: 'client'
        password: 'client-secret'
      tenantx:
        principal: 'tenantx'
        password: my-secret
      tenanty:
        principal: 'tenanty'
        password: my-secret
    
    #### TLS Configuration ####
    ## By default, data will NOT be encrypted. To turn on TLS encryption, uncomment this line
    # ssl_enabled: true
    ## By default, the components will be configured with One-Way TLS, to turn on TLS mutual auth, uncomment this line:
    # ssl_mutual_auth_enabled: true
    ## By default, the certs for this configuration will be self signed, to deploy custom certificates there are two options.
    ## Option 1: Custom Certs
    ## You will need to provide the path to the Certificate Authority Cert used to sign each hosts' certs
    ## As well as the signed certificate path and the key for that certificate for each host.
    ## These will need to be set for the correct host
    # ssl_custom_certs: true
    # ssl_custom_certs_remote_src: true # set to true if key crt and ca file already on hosts, file paths must still be set
    # ssl_ca_cert_filepath: "/tmp/certs/ca.crt" # Can be a bundle of ca certs to be included in truststore
    # ssl_signed_cert_filepath: "/tmp/certs/{{inventory_hostname}}-signed.crt" # Can be a full chain of certs
    # ssl_key_filepath: "/tmp/certs/{{inventory_hostname}}-key.pem"
    # ssl_key_password: <password for key for each host, will be inputting in the form -passin pass:{{ssl_key_password}} >
    # regenerate_keystore_and_truststore: true # Set to true to update certs on hosts. If keystores/truststores exist, they won't be updated without this variable.
    ## (Optional) provide custom password for the generated truststores and keystores
    # ssl_keystore_and_truststore_custom_password: true
    # ssl_truststore_password: <mytruststorecustompassword> can be set for each host or service
    # ssl_keystore_store_password: <mykeystorecustompassword> can be set for each host or service
    ## Option 2: Custom Keystores and Truststores (either on control node or the component nodes)
    ## CP-Ansible can move keystores/truststores to their corresponding hosts and configure the components to use them. Set These vars
    # ssl_provided_keystore_and_truststore: true
    # ssl_keystore_filepath: "/tmp/certs/{{inventory_hostname}}-keystore.jks"
    # ssl_keystore_key_password: mystorepassword
    # ssl_keystore_store_password: mystorepassword
    # ssl_keystore_alias: <alias for host specific certificate, only required if multiple certs in provided keystore>
    # ssl_truststore_filepath: "/tmp/certs/truststore.jks"
    # ssl_truststore_password: truststorepass
    # ssl_truststore_ca_cert_alias: <alias to the ca certificate in the truststore eg. CARoot>
    ## Use this if you want to provide keystore/truststore already present on the host. Set the above vars for each component separately if this is enabled.
    # ssl_provided_keystore_and_truststore_remote_src: true

    #### Zookeeper TLS Configuration ####
    ## Zookeeper can also have TLS Encryption and mTLS Authentication
    ## Zookeeper's TLS settings are inherited from the ssl_enabled settings.
    ## If you have ssl_enabled, but want zookeeper without TLS, uncomment these lines
    # zookeeper_ssl_enabled: false
    # zookeeper_ssl_mutual_auth_enabled: false

    #### Kafka Controller TLS Configuration ####
    ## Controller can also have TLS Encryption and mTLS Authentication
    ## Controller's TLS settings are inherited from the ssl_enabled settings.
    ## If you have ssl_enabled, but want controller without TLS, uncomment these lines
    # kafka_controller_ssl_enabled: false
    # kafka_controller_ssl_mutual_auth_enabled: false

    #### Certificate Regeneration ####
    ## When using self signed certificates, each playbook run will regenerate the CA, to turn this off, uncomment this line:
    # regenerate_ca: false
    ## By default, the playbook will recreate them keystores and truststores on each run,
    ## To prevent this, uncomment this line:
    # regenerate_keystore_and_truststore: false

    #### Monitoring Configuration ####
    ## Jolokia is disabled by default. When enabled, Jolokia jar gets pulled from the internet and enabled on all the components
    ## To enable, uncomment this line:
    # jolokia_enabled: true
    ## To copy from control host instead of downloading from remote URL:
    # jolokia_url_remote: false
    ## During setup, the hosts will download the jolokia agent jar from Maven. To update that jar download set this var
    # jolokia_jar_url: http://<inteneral-server>/jolokia-jvm-1.6.2-agent.jar
    ## JMX Exporter is disabled by default. When enabled, JMX Exporter jar will be pulled from the Internet and enabled on the broker and zookeeper *only*.
    ## To enable, uncomment this line:
    # jmxexporter_enabled: true
    ## To update that jar download set this var
    # jmxexporter_jar_url: http://<internal-server>/jmx_prometheus_javaagent-0.12.0.jar
    ## To copy from control host instead of downloading from remote URL:
    # jmxexporter_url_remote: false

    #### Custom Yum Repo File (Rhel/Centos) ####
    ## If you are using your own yum repo server to host the packages, in the case of an air-gapped environment,
    ## use the below variables to distribute a custom .repo file to the hosts and skip our repo setup.
    ## Note, your repo server must host all confluent packages
    # repository_configuration: custom
    # custom_yum_repofile_filepath: /tmp/my-repo.repo

    #### Custom Apt Repo File (Ubuntu/Debian) ####
    ## If you are using your own apt repo server to host the packages, in the case of an air-gapped environment,
    ## use the below variables to distribute a custom .repo file to the hosts and skip our repo setup.
    ## Note, your repo server must host all confluent packages
    # repository_configuration: custom
    # custom_apt_repo_filepath: "/tmp/my-source.list"

    #### Confluent Server vs Confluent Kafka ####
    ## Confluent Server will be installed by default, to install confluent-kafka instead, uncomment the below
    confluent_server_enabled: true
    kafka_broker_rest_proxy_enabled: true

    #### Schema Validation ####
    ## Schema Validation with the kafka configuration is disabled by default. To enable uncomment this line:
    ## Schema Validation only works with confluent_server_enabled: true
    # kafka_broker_schema_validation_enabled: true

    #### Fips Security ####
    ## To enable Fips for added security, uncomment the below line.
    ## Fips only works with ssl_enabled: true and confluent_server_enabled: true
    # fips_enabled: true

    #### Configuring Multiple Listeners ####
    ## CP-Ansible will configure two listeners on the broker: a broker listener for the broker to communicate and an internal for the components and other clients.
    ## If you only need one listener uncomment this line:
    # kafka_broker_configure_multiple_listeners: false
    ## By default both of these listeners will follow whatever you set for ssl_enabled and sasl_protocol.
    ## To configure different security settings on the internal and external listeners set the following variables:
    kafka_broker_custom_listeners:
      broker:
        name: BROKER
        port: 9091
        ssl_enabled: false
        ssl_mutual_auth_enabled: false
        sasl_protocol: none
      internal:
        name: INTERNAL
        port: 9092
        ssl_enabled: false
        ssl_mutual_auth_enabled: false
        sasl_protocol: none
      client_listener:
        name: CLIENT
        port: 9093
        ssl_enabled: false
        ssl_mutual_auth_enabled: false
        sasl_protocol: plain

    #### Creating Connectors ####
    ## To manage the connector configs from Ansible, set the following list of connector objects:
    ## one per connector, must have `name` and `config` properties
    ## make sure to provide the numeric values as strings
    # kafka_connect_connectors:
    #   - name: sample-connector
    #     config:
    #       connector.class: "org.apache.kafka.connect.tools.VerifiableSinkConnector"
    #       tasks.max: "1"
    #       file: "path/to/file.txt"
    #       topics: "test_topic"

    #### Configuring logredactor ####
    ## To configure logredactor for all components, set the following variables ##
    # logredactor_enabled: true
    # logredactor_rule_path_local: <path to rule file on local>
    # # Something like ../../../rules.json
    # logredactor_rule_path: <path to rule file on component node>
    # logredactor_policy_refresh_interval: 7000
    kafka_broker_service_environment_overrides: 
        KAFKA_HEAP_OPTS: -Xms2g -Xmx2g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80
    #### Configuring Role Based Access Control ####
    ## To have CP-Ansible configure Components for RBAC and create necessary role bindings, set these mandatory variables:
    ## Note: Confluent components will be configured to connect to the "internal" listener automatically
    ## DO NOT UPDATE the internal listener
    ## Note: It is recommended to create an additional listener for external clients, but the interbroker listener would also work
    ## Note: An authentication mode must be selected on all listeners, for example (ssl_enabled=false and ssl_mutual_auth_enabled=false) or sasl_protocol=none is not supported.
    # rbac_enabled: true
    ##
    ## LDAP Users
    ## Note: Below users must already exist in your LDAP environment.  See kafka_broker vars, for LDAP connection details.
    # mds_super_user: <Your mds super user which has the ability to bootstrap RBAC roles and permissions>
    # mds_super_user_password: <ldap password>
    # kafka_broker_ldap_user: <Your Embedded Rest Proxy username in LDAP>
    # kafka_broker_ldap_password: <Your Embedded Rest Proxy user's LDAP password>
    # schema_registry_ldap_user: <Your Schema Registry username in LDAP>
    # schema_registry_ldap_password <Your schema registry user's LDAP password>
    # kafka_connect_ldap_user: <Your Connect username in LDAP>
    # kafka_connect_ldap_password: <Your Connect user's password in LDAP>
    # ksql_ldap_user: <Your KSQL username in LDAP>
    # ksql_ldap_password: <Your KSQL user's password in LDAP>
    # kafka_rest_ldap_user: <Your REST Proxy's username in LDAP>
    # kafka_rest_ldap_password: <Your REST Proxy's password in LDAP>
    # control_center_ldap_user: <Your Control Center username in LDAP>
    # control_center_ldap_password: <Your Control Center password in LDAP>
    ## Below are optional variables
    # create_mds_certs: false # To provide your own MDS Certs set this variable and the next two
    # token_services_public_pem_file: /path/to/public.pem
    # token_services_private_pem_file: /path/to/tokenKeypair.pem
    # mds_acls_enabled: false #to turn off mds based acls, they are on by default if rbac is on
    # kafka_broker_rest_ssl_enabled: true/false #defaults to whatever ssl_enabled var is set to
    ## Allow the playbooks to configure additional principals as system admins on the platform, set the list below
    # rbac_component_additional_system_admins:
    #   - User:user1
    #   - Group:group1
    ##
    ####  Configuring Role Based Access Control with a remote MDS ####
    ## To have CP-Ansible configure Brokers and Components for RBAC with the MDS on a remote Kafka cluster, set these mandatory variables in addition to those listed above:
    # rbac_enabled: true
    # external_mds_enabled: true
    ## The URL for the MDS REST API on your Kafka Cluster hosting MDS
    # mds_bootstrap_server_urls: http(s)://<mds-broker-hostname>:8090,http(s)://<mds-broker-hostname>:8090
    ## The URL and Port for the listener on your Kafka Cluster hosting the MDS that you wish to connect to
    # mds_broker_bootstrap_servers: <mds-broker-hostname><port>,<mds-broker-hostname><port>
    ## Configure the security settings to match the same listener as defined in the mds_broker_bootstrap_servers
    # mds_broker_listener:
    #   ssl_enabled: true <set to false if remote MDS does not use TLS>
    #   ssl_mutual_auth_enabled: true <set to false if remote MDS doe not use MTLS>
    #   sasl_protocol: none <set protocol for remote MDS, options are: kerberos, sasl_plain, sasl_scram>
    ##
    # kafka_controller_ldap_user: <Your Kafka Controller username in LDAP, works only when rbac_enabled is true>
    # kafka_controller_ldap_password: <Your Kafka Controller user's LDAP password>
    ## By default the Confluent CLI will be installed on each host *when rbac is enabled*, to stop this download set:
    # confluent_cli_download_enabled: false
    ## CLI will be downloaded from Confluent's webservers, to customize the location of the binary set:
    # confluent_cli_custom_download_url: <URL to custom webserver hosting for confluent cli>

    ## Configuring Telemetry
    ## Set the below required variables
    # telemetry_enabled: false
    # telemetry_api_key: XXXXXX
    # telemetry_api_secret: YYYYYYYYY

    ## To set custom properties for each service
    ## Find property options in the Confluent Documentation
    # zookeeper_custom_properties:
    #   initLimit: 6
    #   syncLimit: 3
    
    kafka_broker_metrics_reporter_enabled: true
    kafka_broker_custom_properties:
      confluent.metrics.reporter.bootstrap.servers: "kafka.xyzdemo.io:9092"

    # kafka_broker_custom_client_properties:
    #   zookeeper.ssl.protocol: TLSv1.3
    # schema_registry_custom_properties:
    #   key: val
    # control_center_custom_properties:
    #   key: val
    # kafka_connect_custom_properties:
    #   key: val
    # kafka_rest_custom_properties:
    #   key: val
    # ksql_custom_properties:
    #   key: val

kafka_controller:
  hosts:
    broker-001:
    broker-002:
    broker-003:

kafka_broker:
  hosts:
    broker-004:
    broker-005:
    broker-006:
